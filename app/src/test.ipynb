{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# App Libs\n","from gather.gather import Gather\n","from prof.profile import Profile\n","from clean.clean import Clean\n","from feature_engineering.engineer import Engineering\n","\n","from automate.automate import Automate\n","\n","from utils.utils import has_missing_data\n","from utils.utils import plot_convergence_random\n","# from utils.utils import results\n","\n","from sklearn.model_selection import train_test_split\n","from skopt.plots import plot_convergence\n","from skopt.plots import plot_evaluations\n","from skopt.plots import plot_objective\n","\n","# Generic\n","import random\n","import pandas as pd\n","\n","# Warnings\n","import warnings\n","\n","# Settings\n","warnings.filterwarnings('ignore', category=UserWarning)\n","warnings.filterwarnings('ignore', category=RuntimeWarning)\n","pd.set_option('display.max_columns', None)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Titanic Data | GOOD\n","tn_filepath = '../../data/sample_data/titanic/train.csv'\n","tn_target = 'Survived'\n","\n","# Adult | VERY GOOD\n","at_filepath = '../../data/sample_data/adult/adult.csv'\n","at_target = 'income'\n","\n","# Bank Marketing | Kaggle | VERY GOOD\n","bk_filepath = '../../data/sample_data/bank/bank.csv'\n","bk_target = 'deposit'\n","\n","# Raisin | INTER\n","rs_filepath = '../../data/sample_data/raisin/Raisin_Dataset.csv'\n","rs_target = 'Class'\n","\n","# Credit Fraud\n","# cc_filepath = '../../data/sample_data/credit_card_fraud/creditcard.csv'\n","# cc_target = 'Class'\n","\n","# Rain Australia\n","ra_filepath = '../../data/sample_data/rainAustralia/weatherAUS.csv'\n","ra_target = 'RainTomorrow'\n","\n","# Diabetes \n","db_filepath = '../../data/sample_data/diabetes/diabetes.csv'\n","db_target = 'Outcome'\n","\n","# Heart Disease\n","hd_filepath = '../../data/sample_data/heart/heart.csv'\n","hd_target = 'target'\n","\n","# Ada prior\n","ad_filepath = '../../data/sample_data/ada_prior/ada_prior.csv'\n","ad_target = 'label'\n","\n","# Egg\n","eg_filepath = '../../data/sample_data/egg/dataset.arff'\n","eg_target = ''\n","\n","# Obesity\n","ob_filepath = '../../data/sample_data/obesity/obesity.csv'\n","ob_target = 'NObeyesdad' \n","\n","# Mozilla\n","mo_filepath = '../../data/sample_data/mozilla/mozilla.arff'\n","mo_target = 'state'\n","\n","# Page Blocks\n","pb_filepath = '../../data/sample_data/page_blocks/page_blocks.arff'\n","pb_target = 'class'\n","\n","# Page Blocks\n","pcb_filepath = '../../data/sample_data/pcb/cirrhosis.csv'\n","pcb_target = 'Status'\n","\n","# Loan Default\n","ld_filepath = '../../data/sample_data/loan_default/Loan_default.csv'\n","ld_target = 'y'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["auto_params = {\n","    'filepath' : at_filepath,\n","    'target' : at_target,\n","    'problem_type' : 'classification',\n","    'model' : 'ensemble',\n","    'opt_method': 'bayesian',\n","    'n_iter' : 50\n","}\n","automate = Automate(auto_params)\n","res = automate.auto_preproc()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def results(opt_type, res):\n","    if (opt_type == 'bayesian'):\n","\n","        print(f\"---- Auto Analysis Report ----\")\n","\n","        # Best Accuracy\n","        print(\"\\n\")\n","        print(f\"Best Accuracy: {round(1 - res['fun'], 4)}\")\n","        print(f\"Total Running Time: 0.15 seconds\\n\")\n","\n","        # Suggested Pipeline\n","        print(f\"Suggested Pipeline: \\n\")\n","\n","        pip = res['x']\n","\n","        # Outliers\n","        outlier_thres = pip[2]\n","        print(f\"Outlier IQR Threshold: {outlier_thres}\")\n","\n","        # Imputation\n","        imputation_method = pip[3].title()\n","        print(f\"Imputation Type: {imputation_method}\")\n","\n","        # Encode \n","        encode_type = 'One-hot' if pip[5] == 'one-hot' else 'Label'\n","        print(f\"Encoding Type: {encode_type}\")\n","\n","        # Scale\n","        scale_type = pip[6].title()\n","        print(f\"Scale Type: {scale_type}\")\n","\n","        # Selection\n","        selection_type = pip[7].title()\n","        print(f\"Selection Type: {selection_type}\")\n","\n","        # Selection Percentage\n","        selection_perc = pip[8] * 100\n","        print(f\"Selection Percentage: {selection_perc} %\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["res"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results(auto_params['opt_method'], res)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_convergence(res)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_evaluations(res)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["res['x']"]},{"cell_type":"markdown","metadata":{},"source":["## Optimizationk"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","\n","# Logistic regression model\n","log_reg = LogisticRegression(max_iter=100)\n","\n","# Hyperparameter grid\n","param_grid = {\n","    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n","    'C': [0.01, 0.1, 1, 10, 100],\n","    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'saga'],\n","    'l1_ratio': [None, 0.5]  # Only used if penalty is 'elasticnet'\n","}\n","# \n","# Labels\n","y_train = automate.X_train_preprocessed[ra_target]\n","y_test = automate.X_test_preprocessed[ra_target]\n","\n","# Drop Targets\n","x_train = automate.X_train_preprocessed.drop(columns=[ra_target])\n","x_test = automate.X_test_preprocessed.drop(columns=[target']])\n","\n","\n","# Grid search\n","bayes_search = BayesSearchCV(estimator=log_reg, search_spaces=param_space, n_iter=32, cv=5, n_jobs=-1, scoring='accuracy')\n","\n","# Best parameters\n","print(\"Best Hyperparameters:\", grid_search.best_params_)\n","print(\"Best Accuracy:\", grid_search.best_score_)"]},{"cell_type":"markdown","metadata":{},"source":["## TestingArea"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["profile_params = {'cat_thres': 0.15, 'id_thres': 0.9}\n","clean_params ={'drop_thres': 0.6, 'outlier_thres': 2, 'num_type': 'mean'}\n","engineer_params = {'freq_thres': 0.11573224634366791, 'encode_type': 'one-hot', 'scale': True, 'scale_type': 'min-max', 'select': True, 'select_type': 'variance_thres'} "]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["gather = Gather(ra_filepath, ra_target)\n","df = gather.gather()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["profile = Profile(df, mo_target, profile_params)\n","prof = profile.df_profile()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)\n","\n","clean = Clean(X_train, X_test, prof, clean_params)\n","cleaned = clean.clean(profile_params)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["eng_profile = Profile(clean.get_train, mo_target, profile_params)\n","eng_prof = eng_profile.df_profile()\n","\n","engineer = Engineering(clean.get_train, clean.get_test, eng_prof, mo_target, engineer_params )\n","eng = engineer.engineer(profile_params)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["engineer.get_train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":2}
